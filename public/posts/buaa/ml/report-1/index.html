<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[BUAA-ML] 第一次实验报告 | oNya's Blog</title>
<meta name=keywords content><meta name=description content="Linear Regression"><meta name=author content="oNya"><link rel=canonical href=%7b%7b%20.Permalink%20%7d%7d><link crossorigin=anonymous href=/assets/css/stylesheet.79e07885fe54214be03f273758b2bda9bbf1210d3eba9e9b5be2955ca8fdb800.css integrity="sha256-eeB4hf5UIUvgPyc3WLK9qbvxIQ0+up6bW+KVXKj9uAA=" rel="preload stylesheet" as=style><link rel=icon href=https://oNya685.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://oNya685.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://oNya685.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://oNya685.github.io/apple-touch-icon.png><link rel=mask-icon href=https://oNya685.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://oNya685.github.io/posts/buaa/ml/report-1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=preconnect href=https://static.zeoseven.com crossorigin><link rel=stylesheet href=https://static.zeoseven.com/zsft/372/main/result.css onerror='this.href="https://static-host.zeoseven.com/zsft/372/main/result.css"'><link rel=stylesheet href=https://static.zeoseven.com/zsft/25/main/result.css onerror='this.href="https://static-host.zeoseven.com/zsft/25/main/result.css"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://oNya685.github.io/posts/buaa/ml/report-1/"><meta property="og:site_name" content="oNya's Blog"><meta property="og:title" content="[BUAA-ML] 第一次实验报告"><meta property="og:description" content="Linear Regression"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-27T21:42:13+08:00"><meta property="article:modified_time" content="2025-04-27T21:42:13+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[BUAA-ML] 第一次实验报告"><meta name=twitter:description content="Linear Regression"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://oNya685.github.io/posts/"},{"@type":"ListItem","position":2,"name":"北京航空航天大学","item":"https://oNya685.github.io/posts/buaa/"},{"@type":"ListItem","position":3,"name":"[BUAA-ML] 第一次实验报告","item":"https://oNya685.github.io/posts/buaa/ml/report-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[BUAA-ML] 第一次实验报告","name":"[BUAA-ML] 第一次实验报告","description":"Linear Regression","keywords":[],"articleBody":"机器学习实验报告\n一、数据预处理：归一化与标准化处理\n（一）实验中的预处理方法\n是否进行归一化/标准化\n实验中使用了 标准化（Standardization） 处理，具体代码为：\nscaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) • fit_transform 对训练集计算均值和标准差并应用转换。\n• transform 对测试集直接使用训练集的参数进行转换。\n归一化与标准化的区别\n• 归一化（Normalization）：\n将数据缩放到固定范围（如[0,1]），公式为：\n\\[ x_{\\text{norm}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}} \\]\n• 标准化（Standardization）：\n将数据调整为均值为0、标准差为1的分布，公式为：\n\\[ x_{\\text{std}} = \\frac{x - \\mu}{\\sigma} \\] 线性回归对特征尺度敏感的原因\n• 解析解稳定性：参数解析解 \\( w = (X^T X)^{-1} X^T y \\) 中，若特征尺度差异大，矩阵 \\( X^T X \\) 的条件数增大，导致求逆不稳定。\n• 梯度下降效率：不同尺度的特征需不同的学习率，尺度差异大会导致收敛速度慢。\n二、线性回归目标函数与参数求解\n（一）目标函数与解析解推导\n目标函数：\n\\[ J(w) = \\sum_{i=1}^N (w^T x_i - y_i)^2 \\] 解析解推导：\n• 矩阵形式：\\( J(w) = (Xw - y)^T (Xw - y) \\)\n• 对 \\( w \\) 求导并令导数为零：\n\\[ \\frac{\\partial J(w)}{\\partial w} = 2X^T (Xw - y) = 0 \\]\n• 解得：\n\\[ w = (X^T X)^{-1} X^T y \\] （二）标准方程组法与梯度下降法的对比\n优势：\n• 精确解：直接得到全局最优解，无需迭代调参。\n• 效率高：当特征数 \\( d \\) 较小时（实验数据集特征数 \\( d=8 \\)），计算复杂度 \\( O(d^3) \\) 可接受。\n劣势：\n• 计算复杂度：若 \\( d \u003e 10^4 \\)，矩阵求逆计算不可行。\n• 内存限制：存储 \\( X^T X \\) 需要 \\( O(d^2) \\) 内存。\n三、模型评估指标分析\n（一）指标定义与意义\n均方误差（MSE）：\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 \\]\n• 反映预测值与真实值的平均平方误差，值越小越好。\n均方根误差（RMSE）：\n\\[ \\text{RMSE} = \\sqrt{\\text{MSE}} \\]\n• 与目标变量单位一致，更易解释误差的实际影响。\n决定系数（R²）：\n\\[ R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2} \\]\n• 表示模型解释的方差比例，范围 \\( (-\\infty, 1] \\)，越接近1越好。\n（二）R²为负的原因\n• 模型性能极差：当 \\( \\sum (y_i - \\hat{y}_i)^2 \u003e \\sum (y_i - \\bar{y})^2 \\)，即模型预测比直接取均值更差。\n• 可能原因：\n数据存在严重噪声或非线性关系未被捕捉。 特征与目标变量无关，模型欠拟合。 四、非线性关系的拟合方法\n（一）问题分析\n直接使用线性回归无法捕捉特征与目标变量之间的非线性关系（如二次函数），导致预测性能下降。\n（二）改进方法\n多项式特征扩展：\n• 添加特征的高次项（如 \\( x^2, x^3 \\)）或交互项（如 \\( x_1 x_2 \\)）。\n• 代码示例：\npoly = PolynomialFeatures(degree=2) X_poly = poly.fit_transform(X) 核方法（Kernel Trick）：\n• 将特征映射到高维空间，间接实现非线性拟合。\n树模型（如决策树、随机森林）：\n• 直接处理非线性关系，但需牺牲模型可解释性。\n（三）实验中的应用建议\n• 在步骤二中引入 PolynomialFeatures 生成多项式特征，再使用线性回归拟合。\n结论\n实验通过标准化处理提升模型稳定性，利用线性回归解析解高效求解参数，并通过评估指标验证模型性能。针对非线性关系，可通过特征工程扩展模型表达能力。\n","wordCount":"1135","inLanguage":"en","datePublished":"2025-04-27T21:42:13+08:00","dateModified":"2025-04-27T21:42:13+08:00","author":{"@type":"Person","name":"oNya"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://oNya685.github.io/posts/buaa/ml/report-1/"},"publisher":{"@type":"Organization","name":"oNya's Blog","logo":{"@type":"ImageObject","url":"https://oNya685.github.io/favicon.ico"}}}</script><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://oNya685.github.io/ accesskey=h title="主页 | oNya's Blog (Alt + H)"><img src=https://oNya685.github.io/ alt aria-label=logo height=30>主页 | oNya's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://oNya685.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://oNya685.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://oNya685.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://oNya685.github.io/links/ title=链接><span>链接</span></a></li><li><a href=https://oNya685.github.io/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://oNya685.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://oNya685.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://oNya685.github.io/posts/buaa/>北京航空航天大学</a></div><h1 class="post-title entry-hint-parent">[BUAA-ML] 第一次实验报告</h1><div class=post-description>Linear Regression</div><div class=post-meta><span title='2025-04-27 21:42:13 +0800 CST'>2025年4月27日</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;1135 words&nbsp;·&nbsp;oNya</div></header><div class=post-content><p>机器学习实验报告</p><hr><p>一、数据预处理：归一化与标准化处理<br>（一）实验中的预处理方法</p><ol><li><p>是否进行归一化/标准化<br>实验中使用了 标准化（Standardization） 处理，具体代码为：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>scaler <span style=color:#f92672>=</span> StandardScaler()
</span></span><span style=display:flex><span>X_train <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(X_train)
</span></span><span style=display:flex><span>X_test <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>transform(X_test)
</span></span></code></pre></div><p>• <code>fit_transform</code> 对训练集计算均值和标准差并应用转换。</p><p>• <code>transform</code> 对测试集直接使用训练集的参数进行转换。</p></li><li><p>归一化与标准化的区别<br>• 归一化（Normalization）：</p><p>将数据缩放到固定范围（如[0,1]），公式为：<br></p>\[
x_{\text{norm}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}
\]<p><br>• 标准化（Standardization）：</p><p>将数据调整为均值为0、标准差为1的分布，公式为：<br></p>\[
x_{\text{std}} = \frac{x - \mu}{\sigma}
\]</li><li><p>线性回归对特征尺度敏感的原因<br>• 解析解稳定性：参数解析解 \( w = (X^T X)^{-1} X^T y \) 中，若特征尺度差异大，矩阵 \( X^T X \) 的条件数增大，导致求逆不稳定。</p><p>• 梯度下降效率：不同尺度的特征需不同的学习率，尺度差异大会导致收敛速度慢。</p></li></ol><hr><p>二、线性回归目标函数与参数求解<br>（一）目标函数与解析解推导</p><ol><li><p>目标函数：<br></p>\[
J(w) = \sum_{i=1}^N (w^T x_i - y_i)^2
\]</li><li><p>解析解推导：<br>• 矩阵形式：\( J(w) = (Xw - y)^T (Xw - y) \)</p><p>• 对 \( w \) 求导并令导数为零：</p>\[
\frac{\partial J(w)}{\partial w} = 2X^T (Xw - y) = 0
\]<p><br>• 解得：</p>\[
w = (X^T X)^{-1} X^T y
\]</li></ol><p>（二）标准方程组法与梯度下降法的对比</p><ol><li><p>优势：<br>• 精确解：直接得到全局最优解，无需迭代调参。</p><p>• 效率高：当特征数 \( d \) 较小时（实验数据集特征数 \( d=8 \)），计算复杂度 \( O(d^3) \) 可接受。</p></li><li><p>劣势：<br>• 计算复杂度：若 \( d > 10^4 \)，矩阵求逆计算不可行。</p><p>• 内存限制：存储 \( X^T X \) 需要 \( O(d^2) \) 内存。</p></li></ol><hr><p>三、模型评估指标分析<br>（一）指标定义与意义</p><ol><li><p>均方误差（MSE）：<br></p>\[
\text{MSE} = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2
\]<p><br>• 反映预测值与真实值的平均平方误差，值越小越好。</p></li><li><p>均方根误差（RMSE）：<br></p>\[
\text{RMSE} = \sqrt{\text{MSE}}
\]<p><br>• 与目标变量单位一致，更易解释误差的实际影响。</p></li><li><p>决定系数（R²）：<br></p>\[
R^2 = 1 - \frac{\sum_{i=1}^N (y_i - \hat{y}_i)^2}{\sum_{i=1}^N (y_i - \bar{y})^2}
\]<p><br>• 表示模型解释的方差比例，范围 \( (-\infty, 1] \)，越接近1越好。</p></li></ol><p>（二）R²为负的原因<br>• 模型性能极差：当 \( \sum (y_i - \hat{y}_i)^2 > \sum (y_i - \bar{y})^2 \)，即模型预测比直接取均值更差。</p><p>• 可能原因：</p><ol><li>数据存在严重噪声或非线性关系未被捕捉。</li><li>特征与目标变量无关，模型欠拟合。</li></ol><hr><p>四、非线性关系的拟合方法<br>（一）问题分析<br>直接使用线性回归无法捕捉特征与目标变量之间的非线性关系（如二次函数），导致预测性能下降。</p><p>（二）改进方法</p><ol><li><p>多项式特征扩展：<br>• 添加特征的高次项（如 \( x^2, x^3 \)）或交互项（如 \( x_1 x_2 \)）。</p><p>• 代码示例：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>poly <span style=color:#f92672>=</span> PolynomialFeatures(degree<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>X_poly <span style=color:#f92672>=</span> poly<span style=color:#f92672>.</span>fit_transform(X)
</span></span></code></pre></div></li><li><p>核方法（Kernel Trick）：<br>• 将特征映射到高维空间，间接实现非线性拟合。</p></li><li><p>树模型（如决策树、随机森林）：<br>• 直接处理非线性关系，但需牺牲模型可解释性。</p></li></ol><p>（三）实验中的应用建议<br>• 在步骤二中引入 <code>PolynomialFeatures</code> 生成多项式特征，再使用线性回归拟合。</p><hr><p>结论<br>实验通过标准化处理提升模型稳定性，利用线性回归解析解高效求解参数，并通过评估指标验证模型性能。针对非线性关系，可通过特征工程扩展模型表达能力。</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://oNya685.github.io/>oNya's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js",function(){pangu.spacingPage()})</script></body></html>
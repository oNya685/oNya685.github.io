<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[BUAA-ML] 第一次实验报告 | oNya's Blog</title>
<meta name=keywords content><meta name=description content="Linear Regression"><meta name=author content="oNya"><link rel=canonical href=%7b%7b%20.Permalink%20%7d%7d><link crossorigin=anonymous href=/assets/css/stylesheet.79e07885fe54214be03f273758b2bda9bbf1210d3eba9e9b5be2955ca8fdb800.css integrity="sha256-eeB4hf5UIUvgPyc3WLK9qbvxIQ0+up6bW+KVXKj9uAA=" rel="preload stylesheet" as=style><link rel=icon href=https://oNya685.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://oNya685.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://oNya685.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://oNya685.github.io/apple-touch-icon.png><link rel=mask-icon href=https://oNya685.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://oNya685.github.io/posts/buaa/ml/report-1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel=stylesheet><link rel=preconnect href=https://static.zeoseven.com crossorigin><link rel=stylesheet href=https://static.zeoseven.com/zsft/372/main/result.css onerror='this.href="https://static-host.zeoseven.com/zsft/372/main/result.css"'><link rel=stylesheet href=https://static.zeoseven.com/zsft/25/main/result.css onerror='this.href="https://static-host.zeoseven.com/zsft/25/main/result.css"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://oNya685.github.io/posts/buaa/ml/report-1/"><meta property="og:site_name" content="oNya's Blog"><meta property="og:title" content="[BUAA-ML] 第一次实验报告"><meta property="og:description" content="Linear Regression"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-27T21:42:13+08:00"><meta property="article:modified_time" content="2025-04-27T21:42:13+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[BUAA-ML] 第一次实验报告"><meta name=twitter:description content="Linear Regression"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://oNya685.github.io/posts/"},{"@type":"ListItem","position":2,"name":"北京航空航天大学","item":"https://oNya685.github.io/posts/buaa/"},{"@type":"ListItem","position":3,"name":"[BUAA-ML] 第一次实验报告","item":"https://oNya685.github.io/posts/buaa/ml/report-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[BUAA-ML] 第一次实验报告","name":"[BUAA-ML] 第一次实验报告","description":"Linear Regression","keywords":[],"articleBody":"一、实验过程中，是否对输入数据进行了归一化或标准化处理？试说明这两种方法的区别，并分析为什么线性回归模型可能对特征的尺度敏感。 （一）实验中的预处理方法 实验中使用了标准化处理：\nscaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) fit_transform对训练集计算均值和标准差并应用转换。 transform对测试集直接使用训练集的参数进行转换。 (二) 归一化与标准化的区别 归一化 (Normalization):\n将数据缩放到固定范围 $[x_{\\min}, x_{\\max}]$，公式为：\n$$ x_{\\text{norm}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}} $$ 标准化 (Standardization):\n将数据调整为均值为0、标准差为1的分布，公式为：\n$$ x_{std} = \\frac{x - \\mu}{\\sigma} $$ (三) 线性回归模型可能对特征的尺度敏感的原因 解析解稳定性\n参数解析解 $w = (X^T X)^{-1} X^T y$ 中，若特征尺度差异大，矩阵 $X^T X$ 的条件数增大，导致求逆不稳定。\n梯度下降效率\n不同尺度的特征需不同的学习率，尺度差异大会导致收敛速度慢。\n二、对于线性回归目标函数 $J(w) = \\sum_{i=1}^N (w^{T} x_i - y_i)^2$，推导给出参数w的解析解形式，并思考对于实验所使用的数据集而言，采用标准方程组法求解参数w相较于梯度下降法有何优势或劣势。 （一）目标函数与解析解推导 目标函数:\n$$ J(w) = \\sum_{i=1}^N (w^T x_i - y_i)^2 $$ 解析解推导:\n矩阵形式：$J(w) = (X w - y)^T (X w - y)$\n对w求导并令导数为零：\n$$ \\frac{\\partial J(w)}{\\partial w} = 2 X^T (X w - y) = 0 $$\n解得：\n$$ w = (X^T X)^{-1} X^T y $$（二）标准方程组法相较于梯度下降法的优劣 优势:\n直接得到全局最优解，无需迭代调参。 当特征数d较小时，计算复杂度 $O(d^3)$ 可接受。 劣势:\n计算复杂度高，过高时矩阵求逆计算不可行。 存储需要 $O(d^2)$ 内存较大。 三、实验中使用的评估指标（如均方误差MSE、均方根误差RMSE、决定系数$R^2$）分别反映了模型的哪些性能？如果某次实验的$R^2$值为负，可能是什么原因导致的？ （一）指标定义与意义 均方误差 (MSE):\n反映预测值与真实值的平均平方误差，值越小越好。\n$$ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y_i})^2 $$ 均方根误差 (RMSE):\n与目标变量单位一致，更易解释误差的实际影响。\n$$ \\text{RMSE} = \\sqrt{\\text{MSE}} $$ 决定系数 ($R^2$):\n表示模型解释的方差比例，范围 $(-\\infty, 1]$，越接近1越好。\n（二）$R^2$为负的原因 $$ R^2 = 1 - \\frac{\\sum_{i=1}^N (y_i - \\bar{y_l})^2}{\\sum_{i=1}^N (y_i - \\bar{y})^2} $$ 模型性能极差：当 $\\sum (y_i - \\hat{y_l})^2 \u003e \\sum (y_i - \\bar{y})^2$，即模型预测比直接取均值更差。 可能原因: 数据存在严重噪声或非线性关系未被捕捉。 特征与目标变量无关，模型欠拟合。 四、在实验中，如果原始数据中存在非线性关系（如特征与目标变量呈二次函数关系），直接使用线性回归会导致模型性能不佳，思考通过何种方式能够更好的拟合特征与目标变量之间的关系。 如果原始数据中存在非线性关系，直接使用线性回归无法捕捉特征与目标变量之间的非线性关系，会导致预测性能下降。\n改进方法 多项式特征扩展：添加特征的高次项（如$x^2, x^3$）或交互项（如$x_1 x_2$）。 核方法：将特征映射到高维空间，间接实现非线性拟合。 树模型（如决策树、随机森林）：直接处理非线性关系，牺牲模型可解释性。 实验中的应用：在步骤二中引入sklearn的PolynomialFeatures生成多项式特征，再使用线性回归拟合。\n五、你对本次实验课程内容、课程形式、实践平台使用等方面有哪些意见及改进建议？ 实践平台的使用不流畅，且无自动补全，最后使用本地IDE才完成。 ","wordCount":"1286","inLanguage":"en","datePublished":"2025-04-27T21:42:13+08:00","dateModified":"2025-04-27T21:42:13+08:00","author":{"@type":"Person","name":"oNya"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://oNya685.github.io/posts/buaa/ml/report-1/"},"publisher":{"@type":"Organization","name":"oNya's Blog","logo":{"@type":"ImageObject","url":"https://oNya685.github.io/favicon.ico"}}}</script><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://oNya685.github.io/ accesskey=h title="主页 | oNya's Blog (Alt + H)"><img src=https://oNya685.github.io/ alt aria-label=logo height=30>主页 | oNya's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://oNya685.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://oNya685.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://oNya685.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://oNya685.github.io/links/ title=链接><span>链接</span></a></li><li><a href=https://oNya685.github.io/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://oNya685.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://oNya685.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://oNya685.github.io/posts/buaa/>北京航空航天大学</a></div><h1 class="post-title entry-hint-parent">[BUAA-ML] 第一次实验报告</h1><div class=post-description>Linear Regression</div><div class=post-meta><span title='2025-04-27 21:42:13 +0800 CST'>2025年4月27日</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;1286 words&nbsp;·&nbsp;oNya</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%b8%80%e5%ae%9e%e9%aa%8c%e8%bf%87%e7%a8%8b%e4%b8%ad%e6%98%af%e5%90%a6%e5%af%b9%e8%be%93%e5%85%a5%e6%95%b0%e6%8d%ae%e8%bf%9b%e8%a1%8c%e4%ba%86%e5%bd%92%e4%b8%80%e5%8c%96%e6%88%96%e6%a0%87%e5%87%86%e5%8c%96%e5%a4%84%e7%90%86%e8%af%95%e8%af%b4%e6%98%8e%e8%bf%99%e4%b8%a4%e7%a7%8d%e6%96%b9%e6%b3%95%e7%9a%84%e5%8c%ba%e5%88%ab%e5%b9%b6%e5%88%86%e6%9e%90%e4%b8%ba%e4%bb%80%e4%b9%88%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e6%a8%a1%e5%9e%8b%e5%8f%af%e8%83%bd%e5%af%b9%e7%89%b9%e5%be%81%e7%9a%84%e5%b0%ba%e5%ba%a6%e6%95%8f%e6%84%9f aria-label=一、实验过程中，是否对输入数据进行了归一化或标准化处理？试说明这两种方法的区别，并分析为什么线性回归模型可能对特征的尺度敏感。>一、实验过程中，是否对输入数据进行了归一化或标准化处理？试说明这两种方法的区别，并分析为什么线性回归模型可能对特征的尺度敏感。</a><ul><li><a href=#%e4%b8%80%e5%ae%9e%e9%aa%8c%e4%b8%ad%e7%9a%84%e9%a2%84%e5%a4%84%e7%90%86%e6%96%b9%e6%b3%95 aria-label=（一）实验中的预处理方法>（一）实验中的预处理方法</a></li><li><a href=#%e4%ba%8c-%e5%bd%92%e4%b8%80%e5%8c%96%e4%b8%8e%e6%a0%87%e5%87%86%e5%8c%96%e7%9a%84%e5%8c%ba%e5%88%ab aria-label="(二) 归一化与标准化的区别">(二) 归一化与标准化的区别</a></li><li><a href=#%e4%b8%89-%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e6%a8%a1%e5%9e%8b%e5%8f%af%e8%83%bd%e5%af%b9%e7%89%b9%e5%be%81%e7%9a%84%e5%b0%ba%e5%ba%a6%e6%95%8f%e6%84%9f%e7%9a%84%e5%8e%9f%e5%9b%a0 aria-label="(三) 线性回归模型可能对特征的尺度敏感的原因">(三) 线性回归模型可能对特征的尺度敏感的原因</a></li></ul></li><li><a href=#%e4%ba%8c%e5%af%b9%e4%ba%8e%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0-jw--sum_i1n-wt-x_i---y_i2%e6%8e%a8%e5%af%bc%e7%bb%99%e5%87%ba%e5%8f%82%e6%95%b0w%e7%9a%84%e8%a7%a3%e6%9e%90%e8%a7%a3%e5%bd%a2%e5%bc%8f%e5%b9%b6%e6%80%9d%e8%80%83%e5%af%b9%e4%ba%8e%e5%ae%9e%e9%aa%8c%e6%89%80%e4%bd%bf%e7%94%a8%e7%9a%84%e6%95%b0%e6%8d%ae%e9%9b%86%e8%80%8c%e8%a8%80%e9%87%87%e7%94%a8%e6%a0%87%e5%87%86%e6%96%b9%e7%a8%8b%e7%bb%84%e6%b3%95%e6%b1%82%e8%a7%a3%e5%8f%82%e6%95%b0w%e7%9b%b8%e8%be%83%e4%ba%8e%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95%e6%9c%89%e4%bd%95%e4%bc%98%e5%8a%bf%e6%88%96%e5%8a%a3%e5%8a%bf aria-label="二、对于线性回归目标函数 $J(w) = \sum_{i=1}^N (w^{T} x_i - y_i)^2$，推导给出参数w的解析解形式，并思考对于实验所使用的数据集而言，采用标准方程组法求解参数w相较于梯度下降法有何优势或劣势。">二、对于线性回归目标函数 $J(w) = \sum_{i=1}^N (w^{T} x_i - y_i)^2$，推导给出参数w的解析解形式，并思考对于实验所使用的数据集而言，采用标准方程组法求解参数w相较于梯度下降法有何优势或劣势。</a><ul><li><a href=#%e4%b8%80%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0%e4%b8%8e%e8%a7%a3%e6%9e%90%e8%a7%a3%e6%8e%a8%e5%af%bc aria-label=（一）目标函数与解析解推导>（一）目标函数与解析解推导</a></li><li><a href=#%e4%ba%8c%e6%a0%87%e5%87%86%e6%96%b9%e7%a8%8b%e7%bb%84%e6%b3%95%e7%9b%b8%e8%be%83%e4%ba%8e%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95%e7%9a%84%e4%bc%98%e5%8a%a3 aria-label=（二）标准方程组法相较于梯度下降法的优劣>（二）标准方程组法相较于梯度下降法的优劣</a></li></ul></li><li><a href=#%e4%b8%89%e5%ae%9e%e9%aa%8c%e4%b8%ad%e4%bd%bf%e7%94%a8%e7%9a%84%e8%af%84%e4%bc%b0%e6%8c%87%e6%a0%87%e5%a6%82%e5%9d%87%e6%96%b9%e8%af%af%e5%b7%aemse%e5%9d%87%e6%96%b9%e6%a0%b9%e8%af%af%e5%b7%aermse%e5%86%b3%e5%ae%9a%e7%b3%bb%e6%95%b0r2%e5%88%86%e5%88%ab%e5%8f%8d%e6%98%a0%e4%ba%86%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%93%aa%e4%ba%9b%e6%80%a7%e8%83%bd%e5%a6%82%e6%9e%9c%e6%9f%90%e6%ac%a1%e5%ae%9e%e9%aa%8c%e7%9a%84r2%e5%80%bc%e4%b8%ba%e8%b4%9f%e5%8f%af%e8%83%bd%e6%98%af%e4%bb%80%e4%b9%88%e5%8e%9f%e5%9b%a0%e5%af%bc%e8%87%b4%e7%9a%84 aria-label=三、实验中使用的评估指标（如均方误差MSE、均方根误差RMSE、决定系数$R^2$）分别反映了模型的哪些性能？如果某次实验的$R^2$值为负，可能是什么原因导致的？>三、实验中使用的评估指标（如均方误差MSE、均方根误差RMSE、决定系数$R^2$）分别反映了模型的哪些性能？如果某次实验的$R^2$值为负，可能是什么原因导致的？</a><ul><li><a href=#%e4%b8%80%e6%8c%87%e6%a0%87%e5%ae%9a%e4%b9%89%e4%b8%8e%e6%84%8f%e4%b9%89 aria-label=（一）指标定义与意义>（一）指标定义与意义</a></li><li><a href=#%e4%ba%8cr2%e4%b8%ba%e8%b4%9f%e7%9a%84%e5%8e%9f%e5%9b%a0 aria-label=（二）$R^2$为负的原因>（二）$R^2$为负的原因</a></li></ul></li><li><a href=#%e5%9b%9b%e5%9c%a8%e5%ae%9e%e9%aa%8c%e4%b8%ad%e5%a6%82%e6%9e%9c%e5%8e%9f%e5%a7%8b%e6%95%b0%e6%8d%ae%e4%b8%ad%e5%ad%98%e5%9c%a8%e9%9d%9e%e7%ba%bf%e6%80%a7%e5%85%b3%e7%b3%bb%e5%a6%82%e7%89%b9%e5%be%81%e4%b8%8e%e7%9b%ae%e6%a0%87%e5%8f%98%e9%87%8f%e5%91%88%e4%ba%8c%e6%ac%a1%e5%87%bd%e6%95%b0%e5%85%b3%e7%b3%bb%e7%9b%b4%e6%8e%a5%e4%bd%bf%e7%94%a8%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e4%bc%9a%e5%af%bc%e8%87%b4%e6%a8%a1%e5%9e%8b%e6%80%a7%e8%83%bd%e4%b8%8d%e4%bd%b3%e6%80%9d%e8%80%83%e9%80%9a%e8%bf%87%e4%bd%95%e7%a7%8d%e6%96%b9%e5%bc%8f%e8%83%bd%e5%a4%9f%e6%9b%b4%e5%a5%bd%e7%9a%84%e6%8b%9f%e5%90%88%e7%89%b9%e5%be%81%e4%b8%8e%e7%9b%ae%e6%a0%87%e5%8f%98%e9%87%8f%e4%b9%8b%e9%97%b4%e7%9a%84%e5%85%b3%e7%b3%bb aria-label=四、在实验中，如果原始数据中存在非线性关系（如特征与目标变量呈二次函数关系），直接使用线性回归会导致模型性能不佳，思考通过何种方式能够更好的拟合特征与目标变量之间的关系。>四、在实验中，如果原始数据中存在非线性关系（如特征与目标变量呈二次函数关系），直接使用线性回归会导致模型性能不佳，思考通过何种方式能够更好的拟合特征与目标变量之间的关系。</a><ul><li><a href=#%e6%94%b9%e8%bf%9b%e6%96%b9%e6%b3%95 aria-label=改进方法>改进方法</a></li></ul></li><li><a href=#%e4%ba%94%e4%bd%a0%e5%af%b9%e6%9c%ac%e6%ac%a1%e5%ae%9e%e9%aa%8c%e8%af%be%e7%a8%8b%e5%86%85%e5%ae%b9%e8%af%be%e7%a8%8b%e5%bd%a2%e5%bc%8f%e5%ae%9e%e8%b7%b5%e5%b9%b3%e5%8f%b0%e4%bd%bf%e7%94%a8%e7%ad%89%e6%96%b9%e9%9d%a2%e6%9c%89%e5%93%aa%e4%ba%9b%e6%84%8f%e8%a7%81%e5%8f%8a%e6%94%b9%e8%bf%9b%e5%bb%ba%e8%ae%ae aria-label=五、你对本次实验课程内容、课程形式、实践平台使用等方面有哪些意见及改进建议？>五、你对本次实验课程内容、课程形式、实践平台使用等方面有哪些意见及改进建议？</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=一实验过程中是否对输入数据进行了归一化或标准化处理试说明这两种方法的区别并分析为什么线性回归模型可能对特征的尺度敏感>一、实验过程中，是否对输入数据进行了归一化或标准化处理？试说明这两种方法的区别，并分析为什么线性回归模型可能对特征的尺度敏感。<a hidden class=anchor aria-hidden=true href=#一实验过程中是否对输入数据进行了归一化或标准化处理试说明这两种方法的区别并分析为什么线性回归模型可能对特征的尺度敏感>#</a></h2><h3 id=一实验中的预处理方法>（一）实验中的预处理方法<a hidden class=anchor aria-hidden=true href=#一实验中的预处理方法>#</a></h3><p>实验中使用了标准化处理：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>scaler <span style=color:#f92672>=</span> StandardScaler()
</span></span><span style=display:flex><span>X_train <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(X_train)
</span></span><span style=display:flex><span>X_test <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>transform(X_test)
</span></span></code></pre></div><ul><li><code>fit_transform</code>对训练集计算均值和标准差并应用转换。</li><li><code>transform</code>对测试集直接使用训练集的参数进行转换。</li></ul><h3 id=二-归一化与标准化的区别>(二) 归一化与标准化的区别<a hidden class=anchor aria-hidden=true href=#二-归一化与标准化的区别>#</a></h3><ol><li><p><strong>归一化 (Normalization)</strong>:<br>将数据缩放到固定范围 $[x_{\min}, x_{\max}]$，公式为：</p>$$ x_{\text{norm}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}} $$</li><li><p><strong>标准化 (Standardization)</strong>:<br>将数据调整为均值为0、标准差为1的分布，公式为：</p>$$ x_{std} = \frac{x - \mu}{\sigma} $$</li></ol><h3 id=三-线性回归模型可能对特征的尺度敏感的原因>(三) 线性回归模型可能对特征的尺度敏感的原因<a hidden class=anchor aria-hidden=true href=#三-线性回归模型可能对特征的尺度敏感的原因>#</a></h3><ol><li><p><strong>解析解稳定性</strong><br>参数解析解 $w = (X^T X)^{-1} X^T y$ 中，若特征尺度差异大，矩阵 $X^T X$ 的条件数增大，导致求逆不稳定。</p></li><li><p><strong>梯度下降效率</strong><br>不同尺度的特征需不同的学习率，尺度差异大会导致收敛速度慢。</p></li></ol><hr><h2 id=二对于线性回归目标函数-jw--sum_i1n-wt-x_i---y_i2推导给出参数w的解析解形式并思考对于实验所使用的数据集而言采用标准方程组法求解参数w相较于梯度下降法有何优势或劣势>二、对于线性回归目标函数 $J(w) = \sum_{i=1}^N (w^{T} x_i - y_i)^2$，推导给出参数w的解析解形式，并思考对于实验所使用的数据集而言，采用标准方程组法求解参数w相较于梯度下降法有何优势或劣势。<a hidden class=anchor aria-hidden=true href=#二对于线性回归目标函数-jw--sum_i1n-wt-x_i---y_i2推导给出参数w的解析解形式并思考对于实验所使用的数据集而言采用标准方程组法求解参数w相较于梯度下降法有何优势或劣势>#</a></h2><h3 id=一目标函数与解析解推导>（一）目标函数与解析解推导<a hidden class=anchor aria-hidden=true href=#一目标函数与解析解推导>#</a></h3><ol><li><p><strong>目标函数</strong>:</p>$$ J(w) = \sum_{i=1}^N (w^T x_i - y_i)^2 $$</li><li><p><strong>解析解推导</strong>:</p></li></ol><p>矩阵形式：$J(w) = (X w - y)^T (X w - y)$</p><p>对w求导并令导数为零：</p>$$ \frac{\partial J(w)}{\partial w} = 2 X^T (X w - y) = 0 $$<p><br>解得：</p>$$ w = (X^T X)^{-1} X^T y $$<h3 id=二标准方程组法相较于梯度下降法的优劣>（二）标准方程组法相较于梯度下降法的优劣<a hidden class=anchor aria-hidden=true href=#二标准方程组法相较于梯度下降法的优劣>#</a></h3><ol><li><p><strong>优势</strong>:</p><ul><li>直接得到全局最优解，无需迭代调参。</li><li>当特征数d较小时，计算复杂度 $O(d^3)$ 可接受。</li></ul></li><li><p><strong>劣势</strong>:</p><ul><li>计算复杂度高，过高时矩阵求逆计算不可行。</li><li>存储需要 $O(d^2)$ 内存较大。</li></ul></li></ol><hr><h2 id=三实验中使用的评估指标如均方误差mse均方根误差rmse决定系数r2分别反映了模型的哪些性能如果某次实验的r2值为负可能是什么原因导致的>三、实验中使用的评估指标（如均方误差MSE、均方根误差RMSE、决定系数$R^2$）分别反映了模型的哪些性能？如果某次实验的$R^2$值为负，可能是什么原因导致的？<a hidden class=anchor aria-hidden=true href=#三实验中使用的评估指标如均方误差mse均方根误差rmse决定系数r2分别反映了模型的哪些性能如果某次实验的r2值为负可能是什么原因导致的>#</a></h2><h3 id=一指标定义与意义>（一）指标定义与意义<a hidden class=anchor aria-hidden=true href=#一指标定义与意义>#</a></h3><ol><li><p><strong>均方误差 (MSE)</strong>:<br>反映预测值与真实值的平均平方误差，值越小越好。<br></p>$$ \text{MSE} = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y_i})^2 $$</li><li><p><strong>均方根误差 (RMSE)</strong>:<br>与目标变量单位一致，更易解释误差的实际影响。<br></p>$$ \text{RMSE} = \sqrt{\text{MSE}} $$</li><li><p><strong>决定系数 ($R^2$)</strong>:<br>表示模型解释的方差比例，范围 $(-\infty, 1]$，越接近1越好。</p></li></ol><h3 id=二r2为负的原因>（二）$R^2$为负的原因<a hidden class=anchor aria-hidden=true href=#二r2为负的原因>#</a></h3>$$ R^2 = 1 - \frac{\sum_{i=1}^N (y_i - \bar{y_l})^2}{\sum_{i=1}^N (y_i - \bar{y})^2} $$<ul><li><strong>模型性能极差</strong>：当 $\sum (y_i - \hat{y_l})^2 > \sum (y_i - \bar{y})^2$，即模型预测比直接取均值更差。</li><li><strong>可能原因</strong>:<ol><li>数据存在严重噪声或非线性关系未被捕捉。</li><li>特征与目标变量无关，模型欠拟合。</li></ol></li></ul><hr><h2 id=四在实验中如果原始数据中存在非线性关系如特征与目标变量呈二次函数关系直接使用线性回归会导致模型性能不佳思考通过何种方式能够更好的拟合特征与目标变量之间的关系>四、在实验中，如果原始数据中存在非线性关系（如特征与目标变量呈二次函数关系），直接使用线性回归会导致模型性能不佳，思考通过何种方式能够更好的拟合特征与目标变量之间的关系。<a hidden class=anchor aria-hidden=true href=#四在实验中如果原始数据中存在非线性关系如特征与目标变量呈二次函数关系直接使用线性回归会导致模型性能不佳思考通过何种方式能够更好的拟合特征与目标变量之间的关系>#</a></h2><p>如果原始数据中存在非线性关系，直接使用线性回归无法捕捉特征与目标变量之间的非线性关系，会导致预测性能下降。</p><h3 id=改进方法>改进方法<a hidden class=anchor aria-hidden=true href=#改进方法>#</a></h3><ol><li><strong>多项式特征扩展</strong>：添加特征的高次项（如$x^2, x^3$）或交互项（如$x_1 x_2$）。</li><li><strong>核方法</strong>：将特征映射到高维空间，间接实现非线性拟合。</li><li><strong>树模型</strong>（如决策树、随机森林）：直接处理非线性关系，牺牲模型可解释性。</li></ol><p><strong>实验中的应用</strong>：在步骤二中引入<code>sklearn</code>的<code>PolynomialFeatures</code>生成多项式特征，再使用线性回归拟合。</p><hr><h2 id=五你对本次实验课程内容课程形式实践平台使用等方面有哪些意见及改进建议>五、你对本次实验课程内容、课程形式、实践平台使用等方面有哪些意见及改进建议？<a hidden class=anchor aria-hidden=true href=#五你对本次实验课程内容课程形式实践平台使用等方面有哪些意见及改进建议>#</a></h2><ul><li>实践平台的使用不流畅，且无自动补全，最后使用本地IDE才完成。</li></ul></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://oNya685.github.io/>oNya's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js",function(){pangu.spacingPage()})</script></body></html>